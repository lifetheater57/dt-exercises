{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOvvWAVTkMR7"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Welcome to the **Few Shot Object Detection for TensorFlow Lite** Colab. Here, we demonstrate fine tuning of a SSD architecture (pre-trained on COCO) on very few examples of a *novel* class. We will then generate a (downloadable) TensorFlow Lite model for on-device inference.\n",
    "\n",
    "**NOTE:** This Colab is meant for the few-shot detection use-case. To train a model on a large dataset, please follow the [TF2 training](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_training_and_evaluation.md#training) documentation and then [convert](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tf2.md) the model to TensorFlow Lite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3U2sv0upw04O"
   },
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vPs64QA1Zdov"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "!python -m pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZcqD4NLdnf4"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import io\n",
    "import imageio\n",
    "import glob\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "tfds = tf.data.Dataset\n",
    "\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "\n",
    "import inspect\n",
    "import sys\n",
    "current_dir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "sys.path.insert(0, parent_dir)\n",
    "from exercise_ws.src.object_detection.include.object_detection.model import Wrapper\n",
    "from exercise_ws.src.object_detection.include.object_detection.dataset import Dataset\n",
    "\n",
    "# To prevent the process to use all the VRAM if not necessary\n",
    "# Also, allow to use a RTX NVIDIA GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IogyryF2lFBL"
   },
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-y9R0Xllefec"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "  \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "  Puts image into numpy array to feed into tensorflow graph.\n",
    "  Note that by convention we put it into a numpy array with shape\n",
    "  (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "  Args:\n",
    "    path: a file path.\n",
    "\n",
    "  Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "  \"\"\"\n",
    "  img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "  image = Image.open(BytesIO(img_data))\n",
    "  (im_width, im_height) = image.size\n",
    "  return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)\n",
    "\n",
    "def plot_detections(image_np,\n",
    "                    boxes,\n",
    "                    classes,\n",
    "                    scores,\n",
    "                    category_index,\n",
    "                    figsize=(12, 16),\n",
    "                    image_name=None,\n",
    "                    class_labels=True,\n",
    "                    score_labels=True,\n",
    "                    min_score_thresh=0.5):\n",
    "  \"\"\"Wrapper function to visualize detections.\n",
    "\n",
    "  Args:\n",
    "    image_np: uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    boxes: a numpy array of shape [N, 4]\n",
    "    classes: a numpy array of shape [N]. Note that class indices are 1-based,\n",
    "      and match the keys in the label map.\n",
    "    scores: a numpy array of shape [N] or None.  If scores=None, then\n",
    "      this function assumes that the boxes to be plotted are groundtruth\n",
    "      boxes and plot all boxes as black with no classes or scores.\n",
    "    category_index: a dict containing category dictionaries (each holding\n",
    "      category index `id` and category name `name`) keyed by category indices.\n",
    "    figsize: size for the figure.\n",
    "    image_name: a name for the image file.\n",
    "  \"\"\"\n",
    "  image_np_with_annotations = image_np.copy()\n",
    "  viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_annotations,\n",
    "      boxes,\n",
    "      classes,\n",
    "      scores,\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      min_score_thresh=min_score_thresh,\n",
    "      line_thickness=1,\n",
    "      skip_scores=not score_labels,\n",
    "      skip_labels=not class_labels)\n",
    "  if image_name:\n",
    "    plt.imsave(image_name, image_np_with_annotations)\n",
    "  else:\n",
    "    plt.imshow(image_np_with_annotations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHlXL1x_Z3tc"
   },
   "source": [
    "# Test .tflite model"
   ]
  },
  {
   "source": [
    "## Load .tflite model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Wrapper(None)"
   ]
  },
  {
   "source": [
    "## Generate prediction from each frame"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcE6OwrHQJya",
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_image_dir = './test/originals'\n",
    "gif_frames_dir = './test/frames'\n",
    "test_images_np = []\n",
    "\n",
    "dataset = Dataset()\n",
    "\n",
    "for i in range(1, 100):\n",
    "  image_path = os.path.join(test_image_dir, str(i) + '.npz')\n",
    "  test_images_np.append(np.expand_dims(np.load(image_path)[\"arr_0\"], axis=0))\n",
    "\n",
    "# Note that the first frame will trigger tracing of the tf.function, which will\n",
    "# take some time, after which inference should be fast.\n",
    "\n",
    "label_id_offset = 1\n",
    "for i in range(len(test_images_np)):\n",
    "  input_tensor = tf.convert_to_tensor(test_images_np[i], dtype=tf.float32)\n",
    "  boxes, classes, scores = model.predict(input_tensor)\n",
    "  if i == 1:\n",
    "    print(boxes, classes, scores)\n",
    "\n",
    "  plot_detections(\n",
    "      test_images_np[i][0],\n",
    "      boxes,\n",
    "      classes.astype(np.uint32) + dataset.label_id_offset,\n",
    "      scores,\n",
    "      dataset.category_index, \n",
    "      figsize=(15, 20), \n",
    "      image_name=gif_frames_dir + \"/gif_frame_\" + ('%02d' % i) + \".jpg\",\n",
    "      min_score_thresh=0.3\n",
    "  )"
   ]
  },
  {
   "source": [
    "## Assemble each processed frames into a GIF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkMPOSQE0x8C",
    "tags": []
   },
   "outputs": [],
   "source": [
    "imageio.plugins.freeimage.download()\n",
    "\n",
    "anim_file = 'duckies_test.gif'\n",
    "\n",
    "filenames = glob.glob(gif_frames_dir + '/gif_frame_*.jpg')\n",
    "filenames = sorted(filenames)\n",
    "last = -1\n",
    "images = []\n",
    "for filename in filenames:\n",
    "  image = imageio.imread(filename)\n",
    "  images.append(image)\n",
    "\n",
    "imageio.mimsave(anim_file, images, 'GIF-FI', fps=5)\n",
    "\n",
    "display(IPyImage(open(anim_file, 'rb').read()))"
   ]
  },
  {
   "source": [
    "# Check the dataset validity"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Process a batch of files"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "check_frames_dir = './check/frames'\n",
    "\n",
    "dataset = Dataset()\n",
    "ragged_batches = dataset.frames.apply(\n",
    "  tf.data.experimental.dense_to_ragged_batch(batch_size=batch_size)\n",
    ")\n",
    "\n",
    "for batch in ragged_batches:\n",
    "    images, gt_boxes, gt_classes = batch\n",
    "    \n",
    "    images_np = images.numpy().astype(np.uint8)\n",
    "    boxes_np = gt_boxes.numpy()\n",
    "    classes_np = gt_classes.numpy()\n",
    "\n",
    "    # Decode one-hot encoding\n",
    "    for i in range(classes_np.shape[0]):\n",
    "        classes_np[i] = np.argmax(classes_np[i], axis=1)\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        if boxes_np[i].shape[0] > 0:\n",
    "          plot_detections(\n",
    "            images_np[i],\n",
    "            boxes_np[i],\n",
    "            classes_np[i].astype(np.uint8) + label_id_offset,\n",
    "            np.ones(boxes_np[i].shape[0]),\n",
    "            dataset.category_index,\n",
    "            figsize=(15, 20),\n",
    "            image_name=check_frames_dir + \"/gif_frame_\" + ('%02d' % i) + \".jpg\",\n",
    "            class_labels=True,\n",
    "            score_labels=False\n",
    "          )\n",
    "    break"
   ]
  },
  {
   "source": [
    "## Assemble each processed frames into a GIF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.plugins.freeimage.download()\n",
    "\n",
    "anim_file = 'duckies_check_db.gif'\n",
    "\n",
    "filenames = glob.glob(check_frames_dir + '/gif_frame_*.jpg')\n",
    "filenames = sorted(filenames)\n",
    "last = -1\n",
    "images = []\n",
    "for filename in filenames:\n",
    "  image = imageio.imread(filename)\n",
    "  images.append(image)\n",
    "\n",
    "imageio.mimsave(anim_file, images, 'GIF-FI', fps=0.5)\n",
    "\n",
    "display(IPyImage(open(anim_file, 'rb').read()))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "eager_few_shot_od_training_tflite.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}